import urllib
from urllib.request import urlopen, Request

import bs4

from crawler_configs import Crawlerconfigs



# CONFIGS
config = Crawlerconfigs()
metropolitans = config.metropolitans    # ë„ì‹œì •ë³´
governments = config.Governments        # í–‰ì •êµ¬ì—­ ì •ë³´

state = None
slot_data = None
positions = (None, None, None)
end_flag = True



def today_dust(location):
    global state, slot_data, positions, end_flag

    try:
        enc_location = urllib.parse.quote(location + ' ì˜¤ëŠ˜ ë‚ ì”¨')
        url = 'https://search.naver.com/search.naver?ie=utf8&query=' + enc_location
        
        locations = location.split(' ')
        req = Request(url)
        page = urlopen(req)
        html = page.read()
        soup = bs4.BeautifulSoup(html, 'html.parser')

        dust_figure = soup.find('dl', class_='indicator')
        dust_figure = dust_figure.text.replace('ã/ã¥', 'ë§ˆì´í¬ë¡œê·¸ë¨í¼ë¯¸í„° ').replace('ppm', 'í”¼í”¼ì—  ').split()
        del dust_figure[0]
        del dust_figure[2]
        del dust_figure[4]
        print("\n[DEBUG1-2]today_dust (dust_figure[5]) >>", dust_figure[5])
        print("\n[DEBUG1-2]today_dust (dust_figure[5]) >>", dust_figure[4], end="\n\n")

        dust = 'ì˜¤ëŠ˜ ' + location + ' ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ì•Œë ¤ë“œë¦´ê²Œìš”!  ğŸ˜ƒ\n\n' + location + 'ì§€ì—­ì˜ ë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + dust_figure[
            1] + ' ì´ê³ , ë†ë„ëŠ” ' + dust_figure[0] + '\n\nì´ˆë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + dust_figure[3] + ' ì´ê³ , ë†ë„ëŠ”' + dust_figure[
                2] + '\n\nì˜¤ì¡´ ìƒíƒœëŠ” ' + dust_figure[5] + ' ì´ê³ , ë†ë„ëŠ” ' + dust_figure[4] + 'ì…ë‹ˆë‹¤!'

        if 'ë‚˜ì¨' in dust:
            dust += 'ê³µê¸° ìƒíƒœê°€ ì•ˆì¢‹ìœ¼ë‹ˆ ë§ˆìŠ¤í¬ë¥¼ ê¼­ ì°©ìš©í•˜ì„¸ìš”!  ğŸ˜·'

    
    except:
        print("############################")
        print("#   DUST CRAWLER ERROR     #")
        print("############################")

        dust = "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ " + location + " ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ì–´ìš”. ğŸ˜¥" + "\n\n" + "ì§€ì—­ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ì‹œ ì•Œë ¤ë“œë¦´ê²Œìš”."

    print("\n\n[DEBUG3-1]today_dust (msg) >>\n", dust)
    return dust, state, slot_data, None, positions, end_flag



def metropolitan(day, location):
    try:
        dust = day + ' ' + location + 'ì˜ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ì•Œë ¤ë“œë¦´ê²Œìš”!  ğŸ˜ƒ'
        enc_location = urllib.parse.quote(location + ' ' + day + ' ë¯¸ì„¸ë¨¼ì§€')
        url = 'https://search.naver.com/search.naver?ie=utf8&query=' + enc_location

        req = Request(url)
        page = urlopen(req)
        html = page.read()
        soup = bs4.BeautifulSoup(html, 'html.parser')

        dust_soup = soup.find_all('dl')
        dust_morn = dust_soup[6].text.split()[1]
        print("[DEBUG1-2]metropolitan (parsing_dust_morn) >>", dust_morn, end="\n")
        dust_noon = dust_soup[7].text.split()[1]
        print("[DEBUG1-2]metropolitan (parsing_dust_noon) >>", dust_noon, end="\n")

        dust += '\n\n' + day + ' ì˜¤ì „ ë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + dust_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + dust_noon
        
        
        enc_location = urllib.parse.quote(location + '+ ' + day + ' ì´ˆë¯¸ì„¸ë¨¼ì§€')
        url = 'https://search.naver.com/search.naver?ie=utf8&query=' + enc_location
        req = Request(url)
        page = urlopen(req)
        html = page.read()
        soup = bs4.BeautifulSoup(html, 'html.parser')
        dust_soup = soup.find_all('dl')
        dust_morn = dust_soup[6].text.split()[1]
        dust_noon = dust_soup[7].text.split()[1]
        dust += '\n\n' + day + ' ì˜¤ì „ ì´ˆë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + dust_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + dust_noon


        enc_location = urllib.parse.quote(location + '+ ' + day + ' ì˜¤ì¡´')
        url = 'https://search.naver.com/search.naver?ie=utf8&query=' + enc_location
        req = Request(url)
        page = urlopen(req)
        html = page.read()
        soup = bs4.BeautifulSoup(html, 'html.parser')
        dust_soup = soup.find_all('dl')
        ozone_morn = dust_soup[6].text.split()[1]
        ozone_noon = dust_soup[7].text.split()[1]
        dust += '\n\n' + day + ' ì˜¤ì „ ì˜¤ì¡´ ìƒíƒœëŠ” ' + ozone_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + ozone_noon + 'ì…ë‹ˆë‹¤'

        if 'ë‚˜ì¨' in dust:
            dust += '\n\nê³µê¸° ìƒíƒœê°€ ë‚˜ì˜ë‹ˆ ë§ˆìŠ¤í¬ë¥¼ ê¼­ ì°©ìš©í•˜ì„¸ìš”!  ğŸ˜·'
    
    except:
        print("############################")
        print("#   DUST CRAWLER ERROR     #")
        print("############################")

        dust = "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ " + location + " ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ì–´ìš”. ğŸ˜¥" + "\n\n" + "ì§€ì—­ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ì‹œ ì•Œë ¤ë“œë¦´ê²Œìš”."

    return dust



def tomorrow_dust(location):
    global state, slot_data, positions, end_flag

    try:
        if len(location.split()) == 1 and location in metropolitans:
            tdust = metropolitan('ë‚´ì¼', location)
        elif len(location.split()) == 1 and location in governments:
            tdust = metropolitan('ë‚´ì¼', location)
        else:
            enc_location = urllib.parse.quote(location + ' ë‚´ì¼ ë¯¸ì„¸ë¨¼ì§€')
            url = 'https://search.naver.com/search.naver?ie=utf8&query=' + enc_location

            req = Request(url)
            page = urlopen(req)
            html = page.read()
            soup = bs4.BeautifulSoup(html, 'html.parser')

            dust_figure = soup.find_all('tbody')[2].text.split()
            dust_figure.remove('ë¯¸ì„¸ë¨¼ì§€')
            dust_figure.remove('ì´ˆë¯¸ì„¸ë¨¼ì§€')
            dust_figure.remove('ì˜¤ì¡´')
            dust_figure.remove('ìì™¸ì„ ')
            dust_figure.remove('í™©ì‚¬')

            tdust = 'ë‚´ì¼ ' + location + ' ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ ì•Œë ¤ë“œë¦´ê²Œìš”!  ğŸ˜ƒ\n\n'
            dust_morn = dust_figure[0]
            print("[DEBUG1-2]tomorrow_dust (dust_morn) >>", dust_morn, end="\n")
            dust_noon = dust_figure[1]
            print("[DEBUG1-2]tomorrow_dust (dust_norn) >>", dust_noon, end="\n")

            tdust += 'ë‚´ì¼ ì˜¤ì „ ë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + dust_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + dust_noon + '\n\n'
            supdust_morn = dust_figure[4]
            supdust_noon = dust_figure[5]
            tdust += 'ë‚´ì¼ ì˜¤ì „ ì´ˆë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + supdust_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + supdust_noon +'\n\n'
            ozone_morn = dust_figure[8]
            ozone_noon = dust_figure[9]
            tdust += 'ë‚´ì¼ ì˜¤ì „ ì˜¤ì¡´ ìƒíƒœëŠ” ' + ozone_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + ozone_noon + 'ì…ë‹ˆë‹¤'

            if 'ë‚˜ì¨' in tdust:
                tdust += '\n\nê³µê¸° ìƒíƒœê°€ ë‚˜ì˜ë‹ˆ ë§ˆìŠ¤í¬ë¥¼ ê¼­ ì°©ìš©í•˜ì„¸ìš”!  ğŸ˜·'
    except:
        print("############################")
        print("#   DUST CRAWLER ERROR     #")
        print("############################")

        tdust = "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ " + location + " ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ì–´ìš”. ğŸ˜¥" + "\n\n" + "ì§€ì—­ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ì‹œ ì•Œë ¤ë“œë¦´ê²Œìš”."

    print("\n\n[DEBUG3-3]tomorrow_dust (msg) >>\n", tdust)
    return tdust, state, slot_data, None, positions, end_flag



def after_tomorrow_dust(location):
    global state, slot_data, positions, end_flag

    try:
        if len(location.split()) == 1 and location in metropolitans:
            dust = metropolitan('ëª¨ë ˆ', location)
        elif len(location.split()) == 1 and location in governments:
            dust = metropolitan('ëª¨ë ˆ', location)
        else:
            enc_location = urllib.parse.quote(location + ' ëª¨ë ˆ ë¯¸ì„¸ë¨¼ì§€')
            url = 'https://search.naver.com/search.naver?ie=utf8&query=' + enc_location

            req = Request(url)
            page = urlopen(req)
            html = page.read()
            soup = bs4.BeautifulSoup(html, 'html.parser')
            dust_figure = soup.find_all('tbody')[2].text.split()
            dust_figure.remove('ë¯¸ì„¸ë¨¼ì§€')
            dust_figure.remove('ì´ˆë¯¸ì„¸ë¨¼ì§€')
            dust_figure.remove('ì˜¤ì¡´')
            dust_figure.remove('ìì™¸ì„ ')
            dust_figure.remove('í™©ì‚¬')

            dust = 'ëª¨ë ˆ ' + location + 'ì˜ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”!  ğŸ˜ƒ\n\n'
            dust_morn = dust_figure[2]
            dust_noon = dust_figure[3]
            dust += 'ëª¨ë ˆ ì˜¤ì „ ë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + dust_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + dust_noon + '\n\n'
            supdust_morn = dust_figure[6]
            supdust_noon = dust_figure[7]
            dust += 'ëª¨ë ˆ ì˜¤ì „ ì´ˆë¯¸ì„¸ë¨¼ì§€ ìƒíƒœëŠ” ' + supdust_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + supdust_noon +'\n\n'
            ozone_morn = dust_figure[10]
            ozone_noon = dust_figure[11]
            dust += 'ëª¨ë ˆ ì˜¤ì „ ì˜¤ì¡´ ìƒíƒœëŠ” ' + ozone_morn + ', ì˜¤í›„ ìƒíƒœëŠ” ' + ozone_noon + 'ì…ë‹ˆë‹¤'

            if 'ë‚˜ì¨' in dust:
                dust += '\n\nê³µê¸° ìƒíƒœê°€ ë‚˜ì˜ë‹ˆ ë§ˆìŠ¤í¬ë¥¼ ê¼­ ì°©ìš©í•˜ì„¸ìš”!  ğŸ˜·'
    except:
        print("############################")
        print("#   DUST CRAWLER ERROR     #")
        print("############################")

        tdust = "ì£„ì†¡í•´ìš”, ì§€ê¸ˆì€ " + location + " ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸ í•  ìˆ˜ ì—†ì–´ìš”.  ğŸ˜¥" + "\n\n" + "ì§€ì—­ì˜ ì´ë¦„ì„ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ì‹œ ì•Œë ¤ë“œë¦´ê²Œìš”."


    print("\n\n[DEBUG3-4]after_tomorrow_dust (msg) >>\n", dust)
    return dust.replace('-', 'ì•„ì§ ì•Œìˆ˜ ì—†ìŒ'), state, slot_data, None, positions, end_flag


# tomorrow_dust("ê°•ì›ë„")