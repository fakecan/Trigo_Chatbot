import re
from random import randint
from urllib.request import Request, urlopen
from urllib.parse import quote
from bs4 import BeautifulSoup

www = 'https://m.search.naver.com/search.naver?query='

# â†’ í”Œë ˆì´ìŠ¤(ê´€ê´‘ì§€)ê²Œì‹œë¬¼ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.
def place_cr(url):
    req = Request(url)
    html = urlopen(req).read()
    soup = BeautifulSoup(html, 'html.parser')
    print('place_cr >>', url, end="\n\n")

    # ì œëª©
    title = soup.find('span', class_ = '_3XamXurMr_').text
    # print("\n\n[DEBUG1-1] place_cr (title) >>", title, end="\n\n")
    content = title + "\n"

    # ì •ë³´
    info = soup.find('ul', class_ = '_6aUG7snIOF')
    info = info.find_all('li', class_ = '_1M_IzKd2N_')

    for item in info:
        label = ''
        item_class = item['class'][1]

        # íŒ¨ìŠ¤ì‹œí‚¬ ì •ë³´
        if item_class in ['_38kvCjMhn9', '_3XI4vbbwyp']: # í‚¤ì›Œë“œ, ì•ˆë‚´
            continue

        # ì£¼ì†Œ **** (íƒœê·¸ ë³€ê²½ë¨ >> item_class ë³€ê²½ë¨)
        # elif item_class == '_1aj6--puXw':
        elif item_class == '_1h3B_0FxjX':
            address = item.find('p', class_='_2yqUQrcZuk').text
            print("\n\n[DEBUG1-1] place_cr (address) >>", address, end="\n\n")
            content += '\nğŸ“¬ ì£¼ì†Œ\n' + item.find('p', class_ = '_2yqUQrcZuk').text + "\n"
        
        # ì˜ì—…ì‹œê°„
        elif item_class == '_2KHqke0mcE':
            biztime = item.find_all('div', class_ = '_2ZP3jVU_Mp')
            content += '\nâ° ì˜ì—…ì‹œê°„\n'
            for i in biztime:
                content += i.text + "\n"
        
        # ìš”ê¸ˆ
        elif item_class == '_1nfcXq8-cV':
            price = item.find_all('div', class_ = '_20Y9lBU_Mw')
            content += '\nğŸ’² ìš”ê¸ˆ'
            for i in price:
                content += '\n'+ i.find('div', class_ = '_2O0eVpLc6z').text
                content += i.find('div', class_ = '_3QTFMQGyTu').text

        # í™ˆí˜ì´ì§€
        elif item_class == '_2iN9byczr4':
            content += '\n\nğŸ  í™ˆí˜ì´ì§€\n' + item.find('a', class_ = '_1RUzg6c8aj').text + "\n\n"

        # ì„¤ëª…
        elif item_class == '_3__3iVrZzf':
            content += '\nğŸ” ì •ë³´\n'
            try: content += item.find('span', class_ = 'WoYOwsMl8Q').text
            except: content += item.find('p', class_ = '_20Y9lBU_Mw').text
        
        # ê·¸ ì™¸
        # else:
        #     if item_class == 'undefined':
        #         content += '\n\n\n[ì£¼ì°¨]\n'

        #     elif item_class == '_3QIuPg9fjo':
        #         content += '\n[ì œê³µ]\n'

        #     else:
        #         label = item_class

        #     content += ' : '+ item.text + "\n\n"

    # ì´ë¯¸ì§€
    try:
        img = soup.find('meta', property = 'og:image')
        if not soup.find('meta', property = 'og:image') == None:
            imgurl = img['content']
    except:
        print("[DEBUG1-1]attraction_crawler place_cr (ERROR)")

    print("\n[DEBUG1-2] attraction_crawler (msg) >>\n", content)
    print("\n[DEBUG1-2] attraction_crawler (imgurl) >>\n", imgurl)
    print("\n[DEBUG1-2] attraction_crawler (url) >>\n", url)
    
    return content, imgurl, url



# ê²€ìƒ‰ëœ í”Œë ˆì´ìŠ¤
def place_link(str_):

    encText = quote(str_)
    url = www + encText
    req = Request(url)
    html = urlopen(req).read()
    soup = BeautifulSoup(html, 'html.parser')
    print('place_link >>',url, end="\n")
    
    find_soup = soup.find('a', class_ = '_1_hm24bR6B') # ëª…ì†Œ
    
    if not find_soup == None:
        url = find_soup['href']
        
        msg, imgurl, info = place_cr(url)

        print('\n\n[DEBUG1-3]place_list (url)\n', info)
        return msg, imgurl, info

    else:
        return None, None, None



# ê²€ìƒ‰ëœ ì¶•ì œ ëª©ë¡
def place_list(str_):
    encText = quote(str_)
    url = 'https://m.search.naver.com/search.naver?query=' + encText
    req = Request(url)
    html = urlopen(req).read()
    soup = BeautifulSoup(html, 'html.parser')
    print('place_list >>',url)
    
    find_soup = soup.find('div', class_ = '_3VuqCwEqtL') # ëª…ì†Œë“¤ì˜ ëª©ë¡
    
    if not find_soup == None:

        # ëª©ë¡
        travel_index = soup.find_all('a', class_ = 'EWKS6nD6CP')
        if len(travel_index) <= 0:
            travel_index = soup.find_all('a', class_ = '_2aE-_9qmC8')

        if len(travel_index) <= 0:
            travel_index = soup.find_all('a', class_ = '_3F_-wxxna5')

        # ëœë¤ìœ¼ë¡œ ê³ ë¥´ê¸°
        len_travel = len(travel_index)
        print(len_travel)
        pick = randint(0, len_travel - 1)
        url = travel_index[pick]['href']

        msg, imgurl, info = place_cr(url)

        print('\n\n[DEBUG1-3]place_list (url)\n', info)
        return msg, imgurl, info

    else:
        return None, None, None